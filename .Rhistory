install.packages("DTK")
summary(gvmodel)
summary(lm.diamonds)
confint(lm.diamonds, level=0.95)
gvmodel <- gvlma(lm.diamonds)
summary(gvmodel)
plot(lm.diamonds)
opar <- par(no.readonly=FALSE)
par(mfrow=c(2,2))
plot(lm.diamonds)
par <- opar
ncvTest(lm.diamonds)
lm.diamonds <- lm(price~carat-depth,data=diamonds)
summary(lm.diamonds)
ggplot(diamonds,aes(x=diamonds$price,y=diamonds$depth))+geom_point()
ggplot(diamonds,aes(x=diamonds$price,y=diamonds$z))+geom_point()
ggplot(diamonds,aes(x=diamonds$price,y=diamonds$y))+geom_point()
ggplot(diamonds,aes(x=diamonds$price,y=diamonds$x))+geom_point()
ggplot(diamonds,aes(x=diamonds$price,y=diamonds$depth))+geom_point()
lm.diamonds <- lm(price~carat,data=diamonds)
summary(lm.diamonds)
confint(lm.diamonds, level=0.95)
gvmodel <- gvlma(lm.diamonds)
summary(gvmodel)
opar <- par(no.readonly=FALSE)
par(mfrow=c(2,2))
plot(lm.diamonds)
par <- opar
ncvTest(lm.diamonds)
spreadLevelPlot(lm.diamonds)
?diamonds
lm.diamonds <- lm(price~carat+depth,data=diamonds)
summary(lm.diamonds)
1542/mean(diamonds$price)
confint(lm.diamonds, level=0.95)
library(gvlma)
gvmodel <- gvlma(lm.diamonds)
summary(gvmodel)
opar <- par(no.readonly=FALSE)
par(mfrow=c(2,2))
plot(lm.diamonds)
par <- opar
#HomoskedaszitÃ¤t
ncvTest(lm.diamonds)
read.table("/Users/wolfganggross/Dropbox/Uni/WS 2013:14/Inf Datenanalyse/10_Praxiskurs/krebs.csv")
krebs <- read.table("/Users/wolfganggross/Dropbox/Uni/WS 2013:14/Inf Datenanalyse/10_Praxiskurs/krebs.csv",sep=",")
krebs
krebs <- read.table("/Users/wolfganggross/Dropbox/Uni/WS 2013:14/Inf Datenanalyse/10_Praxiskurs/krebs.csv",sep=",",header=TRUE)
krebs
library(reshape)
installed.packages()
library(reshape2)
library(reshape)
melt(krebs,var_name=Type)
subset(melt(krebs,var_name="Type")
subset(melt(krebs,var_name="Type")
subset(melt(krebs,var_name="Type")
melt(krebs,var_name="Type")
?melt
?melt()
subset(melt(krebs),melt(krebs)$value!=NA)
kr <- melt(krebs)
subset(kr,kr$value!=NA)
subset(kr,kr$value==NA)
kr[value==NA]
kr[kr$value==NA]
kr[value==NA]
kr$value[NA]
kr$value[!NA]
kr$value[!=NA]
kr
na.omit(kr)
kr<- na.omit(kr)
isfactor(kr$variable)
is.factor(kr$variable)
aov.kr  <- aov(value~variable,data=kr)
summary(aov.kr)
library(ggplot2)
geom_boxplot(kr,aes=(x=variable,y=value))
geom_boxplot(kr,aes(x=variable,y=value))
library(ggplot2)
ggplot(kr,aes(x=variable,y=value))+geom_boxplot()
library(DTK)
install.packages("rjags")
library(rjags)
# Goal: To make a panel of pictures.
par(mfrow=c(3,2))                       # 3 rows, 2 columns.
# Now the next 6 pictures will be placed on these 6 regions. :-)
# Let me take some pains on the 1st
plot(density(runif(100)), lwd=2)
text(x=0, y=0.2, "100 uniforms")        # Showing you how to place text at will
abline(h=0, v=0)
# All these statements effect the 1st plot.
x=seq(0.01,1,0.01)
par(col="blue")                         # default colour to blue.
# 2 --
plot(x, sin(x), type="l")
lines(x, cos(x), type="l", col="red")
# 3 --
plot(x, exp(x), type="l", col="green")
lines(x, log(x), type="l", col="orange")
# 4 --
plot(x, tan(x), type="l", lwd=3, col="yellow")
# 5 --
plot(x, exp(-x), lwd=2)
lines(x, exp(x), col="green", lwd=3)
# 6 --
plot(x, sin(x*x), type="l")
lines(x, sin(1/x), col="pink")
library("rjags")
library("rjags")
installed.packages()
library("rjags")
library("car")
library("ggplot")
install.packages("car")
library("ggplot")
install.packages("ggplot")
install.packages("ggplot2")
library("ggplot2")
library("rjags")
install.packages("rjags")
library("rjags")
library("rjags")
#################################################
source('~/Downloads/506_lecture1/506_lecture1.r', echo=TRUE)
#################################################
# POLS 506: Bayesian Statistics
# Dr. Justin Esarey
# Lecture 1: Conducting a Monte Carlo Assessment
#################################################
#####################################################################
# We will start with an introduction to the basic functions of R.
# NOTE: code preceded by a number sign (#) will not be executed by R
#####################################################################
# How to load data and run basic statistical models
rm(list=ls())       # clear out anything in memory
library(foreign)    # this loads functions that let you read Stata data sets
# Set the working directory of your R session
setwd("C:/jesarey_documents/POLS 506 - Topics in Methodology I/Lecture 1 - Monte Carlo Assessment")
?read.dta    # what does this function do?
my.data.set<-read.dta(file="506_lecture1.dta")  # read.dta() loads the Stata data set, called lecture0.dta
# now we have my.data.set in memory... let's look at it
View(my.data.set)     # View() opens a spreadsheet that lets you see your data frame
# variables in your data set live inside of your data frame.
happiness       # doesn't work!
my.data.set$happiness         # now it works
# if you don't want to reference the data frame every time, you can "attach" it to R's memory.
attach(my.data.set)
happiness
# now, let's do some analysis. What's the relationship between happiness and graduate stipend?
?plot
plot(happiness~stipend)
plot(happiness~stipend, main="Graduate Students: Happiness vs. Stipend", xlab="stipend (in thousands of $)", ylab="happiness (percentile)")
legend("topleft", legend=c("student"), pch=c(1))
# What's the relationship between happiness and year in school?
plot(happiness~years, main="Graduate Students: Happiness vs. Time", xlab="# of years in graduate school", ylab="happiness (percentile)")
# run a (somewhat inappropriate!) linear model relating happiness to stipend and years in school
?lm
linear.model<-lm(happiness~years+stipend)
# show the results
summary(linear.model)
# get the coefficients and VCV matrix
coefficients(linear.model)
vcov(linear.model)
# residuals and predicted values
resid<-residuals(linear.model)
pred<-predict(linear.model)
plot(resid~pred)
plot(resid~years)
# create a dichotomous variable called "happy"
# =1 if happiness > 0.5, =0 otherwise
detach(my.data.set)                                       # detach the data set
my.data.set$happy<-my.data.set$happiness>0.5              # add a variable that meets the specification
View(my.data.set)
my.data.set$happy<-as.numeric(my.data.set$happy)          # change T/F to numeric
View(my.data.set)
attach(my.data.set)
plot(happy~stipend)
plot(happy~years)
# run a logit model
?glm
logit.model<-glm(happy~years+stipend, family=binomial(link="logit"))
summary(logit.model)
# figure out marginal effect of moving years from 0 to 1,
# holding stipend at mean
mean.stipend<-mean(stipend)
predict.data<-data.frame(years=c(2,3), stipend=rep(mean.stipend,2))
change<-predict(logit.model, newdata=predict.data, type="response")
change[2]-change[1]
#
get the coefficients and VCV matrix
coefficients(logit.model)
vcov(logit.model)
# how about a probit?
probit.model<-glm(happy~years+stipend, family=binomial(link="probit"))
summary(probit.model)
# clear everything out again
detach(my.data.set)
rm(list=ls())
##############################
# Basic programming features:
# Scalars and Vectors
##############################
# create a scalar
a<-5
# display it (you can also see it in the "Workspace" pane)
a
# create a vector
b<-c(1,2,3,4,5)     # c() means "concatenate"
# What's the product of a*b?
a*b
# what's the product of two vectors?
d<-c(2,3,2,1,2)
b*d
# what's the sum/difference of two vectors?
b+d
b-d
# What's the third element of b?
b[3]
b[c(1,5)]
b[2:4]
d[2:4]
##############################
# Basic programming features:
# Matrices
#####################
# enter the matrix called A
A<-matrix(c(1,2,3,4,5,6), nrow=3, ncol=3)
# show that matrix
A
# note the difference if we tell to enter by row
AA<-matrix(c(1,2,3,4,5,6), nrow=3, ncol=3, byrow=T)
AA
# element-by-element sum and product of matrices
AA+A
AA*A
# "true" matrix multiplication
AA%*%A
# enter a simple vector x
x<-c(1,2,3,4,5,6)
# change the vector into a matrix
AA<-matrix(x, nrow=3, ncol=3, byrow=T)
AA
# R thinks that a row vector is DIFFERNT than a 1xk matrix
AA<-matrix(x, nrow=1, byrow=T)
AA
is.matrix(x)
is.matrix(AA)
# extract the first row vector
A[1,]
# extract the first column vector
A[,1]
# extract the middle element
A[2,2]
# extract a sub-matrix from matrix A, call it B
B<-A[2:3,2:3]
B
D<-matrix(c(1,2,6,2,4,2), ncol=1)
AA*D  # doesn't work
AA%*%D  # 1x1 scalar
D%*%AA  # 6x6 matrix
##############################
# Basic programming features:
# Arrays
#####################
X<-array(data=runif(36), dim=c(3,3,4))
X
X[1,1,3]
X[3,1,1]
X[,,2]
##############################
# Basic programming features:
# Lists
#####################
Y<-list(one=X[,,1], two=X[,,2], three=X[,,3])
Y$one
Y$two
Y<-list(one=X[,,1], two=X[,,2], three=c("convergence achieved"))
##############################
# Basic programming features:
# Random Variable Generators
#####################
# the uniform
?runif
runif(100)
runif(100, min=-10, max=10)
dunif(5, min=-10, max=10)
# the normal
?rnorm
rnorm(100)
rnorm(100, mean=-2, sd=3)
pnorm(-1.96)
# the multivariate normal
library(mvtnorm)
X<-rmvnorm(1000, mean=c(0,1), sigma=matrix(data=c(1,0,0,1), ncol=2, nrow=2, byrow=T))
plot(X[,1], X[,2])
##############################
# Basic programming features:
# Control Conditions
###############
# for loops
# the fibonacci sequence
a<-c(1,1)
for(i in 3:50){
a[i]<-a[i-1]+a[i-2]
}
# if conditions
# dichotomize a variable
a<-runif(100, min=-5, max=5)  # draw from the uniform distribution
b<-c()                        # empty vector
for(i in 1:length(a)){
if(a[i]>0){
b[i]<-1
}else{
b[i]<-0
}
}
# ...or, you could just do...
bb<-c()
bb<-as.numeric(a>0)
##############################
# Basic programming features:
# Functions
###############
myfunction<-function(a,b){
out<-a^b
return(out)
}
myfunction(2,2)
myfunction.two<-function(A){
out<-A[1]^A[2]
return(out)
}
myfunction.two(c(2,2))
# apply (like a for loop)
?apply
sample.mat<-matrix(data=runif(100), nrow=50, ncol=2)
apply(X=sample.mat, MARGIN=1, FUN=myfunction.two)
store<-c()
for(i in 1:dim(sample.mat)[1]){
store[i]<-myfunction.two(sample.mat[i,])
}
store
#######################################
# Conducting a Monte Carlo study
#######################################
# Question: how well does a LPM approximate a probit DGP?
# set parameters
N<- 100 # data set size
b.int <- 0 # intercept of probit DGP
b.x <- 1 # coefficient on IV
reps <- 1000 # number of times to repeat the simulation
probit.bias<-matrix(data=NA, nrow=reps, ncol=11) # matrix to store bias in probit predictions
linear.bias<-matrix(data=NA, nrow=reps, ncol=11) # matrix to store bias in linear model predictions
pb<-txtProgressBar(initial=0, min=1, max=reps, style=3) # progress bar
for(i in 1:reps){
setTxtProgressBar(pb, value=i)  # update the progress bar
# create a probit data set
x<-runif(N)
u<-rnorm(N, mean=0, sd=1)
ystar<-b.int+b.x*x+u
y<-ifelse(ystar>0, 1, 0)
# values of x over which to predict the data
pred.dat<-data.frame(x=seq(from=0, to=1, by=0.1))
# probit model
probit.mod<-glm(y~x, family=binomial(link="probit"))
# linear model
lin.mod<-lm(y~x)
# predict Pr(y=1) using both models
probit.pred<-predict(probit.mod, type="response", newdata=pred.dat)
lin.pred<-predict(lin.mod, newdata=pred.dat)
# true values
true.pred<-pnorm(b.int+b.x*pred.dat$x, mean=0, sd=1)
# calculate and store bias
probit.bias[i,]<-probit.pred-true.pred
linear.bias[i,]<-lin.pred-true.pred
}
close(pb)   # stop the progress bar
boxplot(probit.bias)
boxplot(linear.bias)
boxplot(probit.bias-linear.bias)
library(ggplot2)
dim(probit.bias)<-c(reps*11, 1)
dim(linear.bias)<-c(reps*11, 1)
bias.dat<-data.frame(bias=rbind(probit.bias, linear.bias), x=factor(rep(seq(from=0, to=1, by=0.1), each=1000), levels=seq(from=0, to=1, by=0.1)), model=factor(rep(c("probit", "linear"), each=reps*11), levels=c("probit", "linear")))
qplot(x, bias, facets=model~., geom="boxplot", data=bias.dat)
qplot(model, bias, facets=~x, geom="boxplot", data=bias.dat)
rm(list=ls())       # clear out anything in memory
library(foreign)    # this loads functions that let you read Stata data sets
?read.dta    # what does this function do?
my.data.set<-read.dta(file="506_lecture1.dta")  # read.dta() loads the Stata data set, called lecture0.dta
#example http://www.johnmyleswhite.com/notebook/2010/08/20/using-jags-in-r-with-the-rjags-package/
library("rjags")
N <- 1000
x <- rnorm(N, 0, 5)
write.table(x,
file = 'example1.data',
row.names = FALSE,
col.names = FALSE)
col.names = FALSE)
col.names = FALSE)
write.table(x,file = 'example1.data',row.names = FALSE,col.names = FALSE)
dat <- read.csv('/Volumes/Macintosh HD/Users/wolfganggross/Desktop/newfile.csv')
dat <- read.csv('/Volumes/Macintosh HD/Users/wolfganggross/Desktop/newfile.csv')
dat <- read.csv('/Volumes/Macintosh HD/Users/wolfganggross/Desktop/newfile1.csv')s
dat <- read.csv('/Volumes/Macintosh HD/Users/wolfganggross/Desktop/newfile1.csv')
dat <- read.csv('/Volumes/Macintosh HD/Users/wolfganggross/Desktop/newfile1.csv',header=false,sep=',')
dat <- read.csv('/Volumes/Macintosh HD/Users/wolfganggross/Desktop/newfile1.csv',header=false,sep=',')
dat <- read.csv('/Volumes/Macintosh HD/Users/wolfganggross/Desktop/newfile1.csv')
View(dat)
View(dat)
libury(ggplot2)
libary(ggplot2)
library(ggplot2)
qplot(dat)
View(dat)
installed.packages
installed.packages()
install.packages('shiny')
defaults write org.R-project.R force.LANG en_US.UTF-8
install.packages('shiny')
system('locale')
system('locale')
install.packages('shiny')
install.packages('shiny')
setwd("~/Documents/programmierung/Social Data Mining All/Social_Data_Mining")
library(slidify)
setwd("~/Documents/programmierung/Social Data Mining All")
library(bit64)
library(data.table)
dat <- readRDS(file="numeric_20140713.Rda")
library(ggplot2)
count = c()
#remove the doubles form dat$Timestamp; get unique
times <- unique(dat$V3)
#table gets number of elements
count  <- data.frame(table(dat$V3))
#sum up per minute and per hour
sumMinute <- c()
for(i in seq(1,length(count$Freq),60)){sumMinute <- append(sumMinute,sum(count$Freq[i:(i+60)]))}
sumHour <- c()
for(k in seq(1,length(count$Freq),3600)){sumHour <- append(sumHour,sum(count$Freq[k:(k+3600)]))}
realTime <- strptime(as.character(count$Var1),format="%Y%m%d%H%M%S")
Tweet.count <- count$Freq
df <- data.frame(realTime,Tweet.count)
ggplot(df,aes(x=realTime,y=Tweet.count)) + geom_line()
df$time <- realTime
df$count <- df$Tweet.count
df$Tweet.count <- NULL
df$realTime <- NULL
df
saveRDS(df,'plot_second13.Rda')
minuteTimestamps <- realTime[seq(1, length(realTime), 60)]
minutePlotDf <- data.frame(minuteTimestamps,sumMinute)
ggplot(minutePlotDf,aes(x=minuteTimestamps,y=sumMinute)) + geom_line()
df$time <- minutePlotDf$minuteTimestamps
minutePlotDf$time <- minutePlotDf$minuteTimestamps
minutePlotDf$count <- minutePlotDf$sumMinute
minutePlotDf$sumMinute  <- NULL
minutePlotDf$minuteTimestamps <- NULL
View(minutePlotDf)
saveRDS(minutePlotDf,'plot_minute13.Rda')
hourTimestamps <- realTime[seq(1, length(realTime), 3600)]
hourPlotDf <- data.frame(hourTimestamps,sumHour)
hourPlotDf$time <- hourPlotDf$hourTimestamps
hourPlotDf$count <- hourPlotDf$sumHour
hourPlotDf$sumHour <- NULL
hourPlotDf$hourTimestamps <- NULL
saveRDS(hourPlotDf,'plot_hour13.Rda')
dat <- readRDS(file="numeric_20140714.Rda")
count = c()
#remove the doubles form dat$Timestamp; get unique
times <- unique(dat$V3)
#table gets number of elements
count  <- data.frame(table(dat$V3))
#sum up per minute and per hour
sumMinute <- c()
for(i in seq(1,length(count$Freq),60)){sumMinute <- append(sumMinute,sum(count$Freq[i:(i+60)]))}
sumHour <- c()
for(k in seq(1,length(count$Freq),3600)){sumHour <- append(sumHour,sum(count$Freq[k:(k+3600)]))}
#####################
#plot
#convert Time into real time format
realTime <- strptime(as.character(count$Var1),format="%Y%m%d%H%M%S")
Tweet.count <- count$Freq
df <- data.frame(realTime,Tweet.count)
ggplot(df,aes(x=realTime,y=Tweet.count)) + geom_line()
df$time <- df$realTime
df$count <- df$Tweet.count
df$Tweet.count
df$Tweet.count <- NULL
df$realTime <- NULL
saveRDS(df,'plot_hour14.Rda')
minuteTimestamps <- realTime[seq(1, length(realTime), 60)]
minutePlotDf <- data.frame(minuteTimestamps,sumMinute)
ggplot(minutePlotDf,aes(x=minuteTimestamps,y=sumMinute)) + geom_line()
minutePlotDf$time <- minutePlotDf$minuteTimestamps
minutePlotDf$count<- minutePlotDf$sumMinute
minutePlotDf$sumMinute <- NULL
minutePlotDf$minuteTimestamps <- NULL
saveRDS(minutePlotDf,'plot_minute14.Rda')
saveRDS(df,'plot_second14.Rda')
hourTimestamps <- realTime[seq(1, length(realTime), 3600)]
hourPlotDf <- data.frame(hourTimestamps,sumHour)
ggplot(hourPlotDf,aes(x=hourTimestamps,y=sumHour)) + geom_line()
hourPlotDf$time <- hourPlotDf$hourTimestamps
hourPlotDf$count <- hourPlotDf$sumHour
hourPlotDf$sumHour <- NULL
hourPlotDf$hourTimestamps <- NULL
saveRDS(hourPlotDf,'plot_hour14.Rda')
setwd("~/Documents/programmierung/Social Data Mining All/Social_Data_Mining")
